{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6강 - 내가 직접 짜보는 순한 맛 딥러닝, 손글씨로 쓴 숫자를 인식해보자 (MNIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서플로(TensorFlow)를 설치합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7. More details about Python 2 support in pip, can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support\u001b[0m\n",
      "Requirement already satisfied: tensorflow in /Users/ps/Library/Python/2.7/lib/python/site-packages (1.14.0)\n",
      "Requirement already satisfied: backports.weakref>=1.0rc1 in /Library/Python/2.7/site-packages (from tensorflow) (1.0.post1)\n",
      "Requirement already satisfied: mock>=2.0.0 in /Users/ps/Library/Python/2.7/lib/python/site-packages (from tensorflow) (3.0.5)\n",
      "Requirement already satisfied: wheel in /Users/ps/Library/Python/2.7/lib/python/site-packages (from tensorflow) (0.33.6)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/ps/Library/Python/2.7/lib/python/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /Users/ps/Library/Python/2.7/lib/python/site-packages (from tensorflow) (0.8.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /Users/ps/Library/Python/2.7/lib/python/site-packages (from tensorflow) (1.16.5)\n",
      "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /Users/ps/Library/Python/2.7/lib/python/site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /Users/ps/Library/Python/2.7/lib/python/site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /Users/ps/Library/Python/2.7/lib/python/site-packages (from tensorflow) (0.1.7)\n",
      "Requirement already satisfied: gast>=0.2.0 in /Users/ps/Library/Python/2.7/lib/python/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: enum34>=1.1.6 in /Users/ps/Library/Python/2.7/lib/python/site-packages (from tensorflow) (1.1.6)\n",
      "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /Users/ps/Library/Python/2.7/lib/python/site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/ps/Library/Python/2.7/lib/python/site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /Users/ps/Library/Python/2.7/lib/python/site-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /Users/ps/Library/Python/2.7/lib/python/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in /Users/ps/Library/Python/2.7/lib/python/site-packages (from tensorflow) (0.8.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Users/ps/Library/Python/2.7/lib/python/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /Users/ps/Library/Python/2.7/lib/python/site-packages (from tensorflow) (1.24.0)\n",
      "Requirement already satisfied: funcsigs>=1; python_version < \"3.3\" in /Users/ps/Library/Python/2.7/lib/python/site-packages (from mock>=2.0.0->tensorflow) (1.0.2)\n",
      "Requirement already satisfied: setuptools in /Users/ps/Library/Python/2.7/lib/python/site-packages (from protobuf>=3.6.1->tensorflow) (41.2.0)\n",
      "Requirement already satisfied: futures>=3.1.1; python_version < \"3\" in /Users/ps/Library/Python/2.7/lib/python/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/ps/Library/Python/2.7/lib/python/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (0.16.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/ps/Library/Python/2.7/lib/python/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: h5py in /Users/ps/Library/Python/2.7/lib/python/site-packages (from keras-applications>=1.0.6->tensorflow) (2.10.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.3.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages\n",
      "Requires: tensorflow-estimator, termcolor, tensorboard, opt-einsum, scipy, wrapt, h5py, numpy, astunparse, google-pasta, gast, keras-preprocessing, wheel, six, grpcio, absl-py, protobuf\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라이브러리를 import 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load_data() 함수를 이용해서 mnist 데이터를 불러옵니다."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0 # 픽셀 range를 0~255에서 0~1로 변경합니다.\n",
    "print(type(x_train))\n",
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터의 일부를 살펴봅시다."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.imshow(x_train[0])\n",
    "print('정답 label :', y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.imshow(x_train[1])\n",
    "print('정답 label :', y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN 모델을 하나 정의합니다."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 손실함수와 옵티마이저를 정의합니다."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.compile(optimizer='sgd',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test 데이터에 대한 mnist 모델의 정확도를 출력합니다."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 예측 결과의 일부를 살펴봅시다."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.imshow(x_test[100])\n",
    "predictions = model.predict(x_test[100:101])\n",
    "print('예측값 :', np.argmax(predictions[0]))\n",
    "print('정답 :', y_test[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연습문제 1 - Fashion MNIST 데이터셋에 대한 분류기를 직접 작성해보자!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0 # 픽셀 range를 0~255에서 0~1로 변경합니다.\n",
    "print(type(x_train))\n",
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터의 일부를 살펴봅시다."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.imshow(x_train[0])\n",
    "print(y_train[0])\n",
    "print('정답 label :', class_names[y_train[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.imshow(x_train[1])\n",
    "print(y_train[1])\n",
    "print('정답 label :', class_names[y_train[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연습문제 1 - Fashin MNIST 분류를 위한 딥러닝 모델을 직접 만들어봅시다.\n",
    "1. 256개의 1개의 히든레이어를 가진 ANN 구조를 만듭니다.\n",
    "2. .compile() 함수를 이용해서 손실함수와 옵티마이저를 정의합니다.\n",
    "3. .fit() 함수를 이용해서 training을 진행합니다.\n",
    "4. .evaluate() 함수를 이용해서 evaluation을 진행합니다.\n",
    "5. .predict() 함수를 이용해서 예측결과의 일부를 시각화해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
